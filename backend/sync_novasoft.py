import pandas as pd
from sqlalchemy import create_engine
from google.cloud.sql.connector import Connector
from urllib.parse import quote_plus
import logging
import os
import traceback

# 1. CARGAR CONFIGURACI√ìN DESDE ENV.YAML
def load_env():
    import yaml
    from pathlib import Path
    # sync_novasoft.py est√° en la carpeta backend/
    # env.yaml est√° en la ra√≠z del proyecto (un nivel arriba)
    root_dir = Path(__file__).resolve().parent.parent
    env_path = root_dir / "env.yaml"
    
    if env_path.exists():
        with open(env_path) as f:
            y = yaml.safe_load(f)
            if y:
                for k, v in y.items():
                    if v is not None:
                        os.environ[k] = str(v)
    else:
        print("‚ö†Ô∏è Advertencia: No se encontr√≥ env.yaml en la ra√≠z.")

load_env()

ERP_USER = os.environ.get("ERP_USER")
ERP_PASS = os.environ.get("ERP_PASS")
ERP_HOST = os.environ.get("ERP_HOST")
ERP_PORT = os.environ.get("ERP_PORT", "5932")
ERP_DB   = os.environ.get("ERP_DB")

# Google Cloud SQL
INSTANCE_CONNECTION_NAME = os.environ.get("CLOUDSQL_CONNECTION_NAME")
CLOUD_USER = os.environ.get("DB_USER")
CLOUD_PASS = os.environ.get("DB_PASS") 
CLOUD_DB   = os.environ.get("DB_NAME")

# 2. MAPEO DE TABLAS (Origen Novasoft: Destino Cloud)
TABLAS_A_SINCRONIZAR = {
    'gen_ccosto': 'dim_proyectos',
    'gen_clasif1': 'dim_fuentes',
    'gen_clasif2': 'dim_componentes',
    'gen_clasif3': 'dim_subcomponentes',
    'gen_clasif4': 'dim_categorias',
    'gen_clasif5': 'dim_responsables'
}

# 3. INICIALIZAR CONECTOR CLOUD SQL
connector = Connector()

def get_cloud_conn():
    return connector.connect(
        INSTANCE_CONNECTION_NAME,
        "pymysql",
        user=CLOUD_USER,
        password=CLOUD_PASS,
        db=CLOUD_DB
    )

def format_id3(val):
    """Rellena con ceros a la izquierda hasta 3 caracteres"""
    s = str(val).strip()
    return s.zfill(3) if s.isdigit() and len(s) <= 3 else s

def sync_table(table_erp, table_cloud, erp_engine, cloud_engine):
    """L√≥gica para subir solo registros nuevos basados en el c√≥digo"""
    print(f"--- üîÑ Procesando tabla: {table_cloud} ---")
    
    try:
        # A. Leer desde Novasoft
        # Ajustamos la consulta seg√∫n la tabla
        if table_erp == 'gen_ccosto':
            query_erp = "SELECT CAST(cod_cco AS VARCHAR(50)) AS codigo, nom_cco AS nombre FROM gen_ccosto WHERE est_cco IS NULL"
        else:
            # Para las gen_clasif, asumimos las dos primeras columnas
            query_erp = f"SELECT TOP 1000 * FROM {table_erp}" 
        
        df_erp = pd.read_sql(query_erp, erp_engine)
        
        # Estandarizar nombres de columnas a 'codigo' y 'nombre'
        # Tomamos las dos primeras columnas sin importar el nombre original
        cols_originales = df_erp.columns.tolist()
        df_erp = df_erp.rename(columns={cols_originales[0]: 'codigo', cols_originales[1]: 'nombre'})
        
        # Limpieza y formato
       
        df_erp['codigo'] = df_erp['codigo'].apply(format_id3)
        df_erp['codigo'] = df_erp['codigo'].str.strip()
        df_erp = df_erp.drop_duplicates(subset=['codigo'], keep='first')

        # B. Leer c√≥digos ya existentes en la Nube (Universo completo para proyectos)
        try:
            if table_cloud == 'dim_proyectos':
                query_existentes = "SELECT codigo FROM dim_proyectos UNION SELECT codigo FROM dim_proyectos_otros"
            else:
                query_existentes = f"SELECT codigo FROM {table_cloud}"
                
            df_existentes = pd.read_sql(query_existentes, cloud_engine)
            codes_in_cloud = set(df_existentes['codigo'].tolist())
        except Exception as e:
            print(f"‚ö†Ô∏è Nota: No se pudo leer existentes en {table_cloud} (posible tabla nueva): {e}")
            codes_in_cloud = set()

        # C. Filtrar: Solo lo que NO est√° en la nube
        df_new = df_erp[~df_erp['codigo'].isin(codes_in_cloud)]

        # D. Cargar solo el diferencial
        if not df_new.empty:
            # Solo enviamos las columnas 'codigo' y 'nombre' para mantener consistencia
            df_new[['codigo', 'nombre']].to_sql(table_cloud, cloud_engine, if_exists='append', index=False)
            print(f"‚úÖ √âxito: Se agregaron {len(df_new)} registros nuevos.")
        else:
            print(f"‚ÑπÔ∏è Al d√≠a: No hay c√≥digos nuevos para agregar.")

    except Exception as e:
        print(f"‚ùå Error procesando {table_cloud}: {e}")
        traceback.print_exc()

def run_sync():
    # Motores de base de datos
    import pyodbc
    drivers = pyodbc.drivers()
    driver = "ODBC Driver 17 for SQL Server"
    if driver not in drivers:
        # Fallback al que est√© disponible que sea para SQL Server
        for d in drivers:
            if "SQL Server" in d:
                driver = d
                break
    
    print(f"‚ÑπÔ∏è Usando driver: {driver}")
    safe_erp_pass = quote_plus(ERP_PASS)
    erp_url = f"mssql+pyodbc://{ERP_USER}:{safe_erp_pass}@{ERP_HOST}:{ERP_PORT}/{ERP_DB}?driver={quote_plus(driver)}"
    erp_engine = create_engine(erp_url)
    
    # Engine de la nube usa el t√∫nel de Google
    cloud_engine = create_engine("mysql+pymysql://", creator=get_cloud_conn)
    
    print("üöÄ Iniciando proceso de sincronizaci√≥n integral...")
    
    for erp_tab, cloud_tab in TABLAS_A_SINCRONIZAR.items():
        sync_table(erp_tab, cloud_tab, erp_engine, cloud_engine)
    
    print("\nüèÅ Proceso finalizado.")

if __name__ == "__main__":
    run_sync()